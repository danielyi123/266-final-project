{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf74da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from torch.amp import autocast\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import logging\n",
    "import json\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import evaluate\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3e201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "MODEL_NAME = \"google/bigbird-pegasus-large-arxiv\"\n",
    "BATCH_SIZE = 36\n",
    "MAX_INPUT_LEN = 2000\n",
    "MAX_OUTPUT_LEN = 600\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TEXT_FIELD = \"text\"  # adjust if your input field is different\n",
    "ID_FIELD = \"title\"\n",
    "OUTPUT_FILE = \"billsum_test_mmr_bigbird_pred.jsonl\"\n",
    "MMR_FILE = \"billsum_test_mmr.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbbd8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): BigBirdPegasusForConditionalGeneration(\n",
       "    (model): BigBirdPegasusModel(\n",
       "      (shared): BigBirdPegasusScaledWordEmbedding(96103, 1024, padding_idx=0)\n",
       "      (encoder): BigBirdPegasusEncoder(\n",
       "        (embed_tokens): BigBirdPegasusScaledWordEmbedding(96103, 1024, padding_idx=0)\n",
       "        (embed_positions): BigBirdPegasusLearnedPositionalEmbedding(4096, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x BigBirdPegasusEncoderLayer(\n",
       "            (self_attn): BigBirdPegasusEncoderAttention(\n",
       "              (self): BigBirdPegasusBlockSparseAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              )\n",
       "              (output): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (activation_fn): NewGELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): BigBirdPegasusDecoder(\n",
       "        (embed_tokens): BigBirdPegasusScaledWordEmbedding(96103, 1024, padding_idx=0)\n",
       "        (embed_positions): BigBirdPegasusLearnedPositionalEmbedding(4096, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x BigBirdPegasusDecoderLayer(\n",
       "            (self_attn): BigBirdPegasusDecoderAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (activation_fn): NewGELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): BigBirdPegasusDecoderAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load Model and Tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "model = torch.compile(model, mode=\"reduce-overhead\", fullgraph=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b3f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2664 records already summarized\n",
      "Dataset length before filter: 3269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3c71d4407f427293092837deec69b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length after filter: 605\n"
     ]
    }
   ],
   "source": [
    "# --- Load Dataset ---\n",
    "billsum_test = load_dataset(\"json\", data_files=\"billsum_data/us_test_data_final_OFFICIAL.jsonl\")[\"train\"]\n",
    "\n",
    "# Track already completed summaries\n",
    "completed_ids = set()\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "                completed_ids.add(record[ID_FIELD])\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "# Filter out completed records\n",
    "print(len(completed_ids), \"records already summarized\")\n",
    "print(\"Dataset length before filter:\", len(billsum_test))\n",
    "billsum_test = billsum_test.filter(lambda x: str(x[ID_FIELD]) not in completed_ids)\n",
    "print(\"Dataset length after filter:\", len(billsum_test))\n",
    "\n",
    "# Exit early if everything is done\n",
    "if len(billsum_test) == 0:\n",
    "    print(\"All entries have already been summarized.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5384956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3269"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MMR summaries\n",
    "mmr = []\n",
    "if os.path.exists(MMR_FILE):\n",
    "    with open(MMR_FILE, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "                mmr.append(record)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "len(mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afeba643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 605/605 [00:00<00:00, 4571.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records found: 605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = {\n",
    "    ID_FIELD: [],\n",
    "    TEXT_FIELD: [],\n",
    "    \"summary\": []\n",
    "}\n",
    "for data in tqdm(billsum_test):\n",
    "    for record in mmr:\n",
    "        if record[ID_FIELD] == data[ID_FIELD]:\n",
    "            data_dict[ID_FIELD].append(record[ID_FIELD])\n",
    "            data_dict[TEXT_FIELD].append(record[TEXT_FIELD])\n",
    "            data_dict[\"summary\"].append(data[\"summary\"])\n",
    "            break\n",
    "       \n",
    "\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "print(\"Records found:\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6f6c1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe81f95feb346c996a74d468a600355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/605 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize all texts\n",
    "def preprocess(example):\n",
    "    tokens = tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_INPUT_LEN,\n",
    "        padding=False\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": tokens[\"input_ids\"],\n",
    "        \"input_len\": len(tokens[\"input_ids\"]),\n",
    "        \"attention_mask\": tokens[\"attention_mask\"]\n",
    "    }\n",
    "\n",
    "print(\"Tokenizing...\")\n",
    "dataset = dataset.map(preprocess, remove_columns=[\"text\"])\n",
    "dataset = dataset.sort(\"input_len\", reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51fef286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating summaries: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [21:16<00:00, 75.10s/it]\n"
     ]
    }
   ],
   "source": [
    "# --- Run Inference ---\n",
    "num_batches = ceil(len(dataset) / BATCH_SIZE)\n",
    "summaries = []\n",
    "all_titles = []\n",
    "with open(OUTPUT_FILE, \"a\") as outfile:\n",
    "    for i in tqdm(range(num_batches), desc=\"Generating summaries\"):\n",
    "        # Extract batch from dataset\n",
    "        start = i * BATCH_SIZE\n",
    "        end = min((i + 1) * BATCH_SIZE, len(dataset))\n",
    "        batch = dataset.select(range(start, end))\n",
    "        \n",
    "        # Pad to max length in batch\n",
    "        padded = tokenizer.pad(\n",
    "            {\n",
    "                \"input_ids\": batch[\"input_ids\"],\n",
    "                \"attention_mask\": batch[\"attention_mask\"]\n",
    "            },\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad(), autocast(\"cuda\"):\n",
    "            outputs = model.generate(\n",
    "                input_ids=padded[\"input_ids\"],\n",
    "                attention_mask=padded[\"attention_mask\"],\n",
    "                max_length=MAX_OUTPUT_LEN,\n",
    "                num_beams=4,\n",
    "                do_sample=False,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3\n",
    "            )\n",
    "\n",
    "        decoded = tokenizer.batch_decode(outputs, skip_special_tokens = True)\n",
    "\n",
    "        for example, summary in zip(batch, decoded):\n",
    "            json.dump({ID_FIELD: example[ID_FIELD], \"prediction\": summary, \"reference\": example[\"summary\"]}, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "        outfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac8c6db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3269\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "references = []\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    with open(OUTPUT_FILE, \"r\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "                predictions.append(record[\"prediction\"])\n",
    "                references.append(record[\"reference\"])\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b06e0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b543379a439438baa0cd751b96c7f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.17589358357783513, 'rouge2': 0.024158811870154152, 'rougeL': 0.11686338195226312, 'rougeLsum': 0.13006141959853468}\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "results = rouge.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c1d3cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2347354f21f34d82abfcab195ba9c242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914a6706b2e340c9990120a5f3e67248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce840cffbc454b1982499db0b8136b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59efa62281544a609233f98ad25d7691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274e2e5116c14aafa4e1e4ebd55b8270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8878958f28304fbbbe8f2b9f1e623ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21537317de14738839e779740454be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c27abe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision: 0.7980728778280444\n",
      "Average recall: 0.7877096881301953\n",
      "Average f1: 0.7923708279113151\n"
     ]
    }
   ],
   "source": [
    "print(f'Average precision: {np.mean(results[\"precision\"])}')\n",
    "print(f'Average recall: {np.mean(results[\"recall\"])}')\n",
    "print(f'Average f1: {np.mean(results[\"f1\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48555a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
